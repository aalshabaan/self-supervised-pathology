{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluate the classifier's transferability on a tiled dataset from Bern cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import Abed_utils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and build model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "patch_size = 8\n",
    "batch_size = 8\n",
    "im_size = 224\n",
    "path_to_backbone = './ckpts/dino_deitsmall8_pretrain.pth'\n",
    "path_to_classifier = './ckpts/classifier_K19_CE_100ep_one_layer.pt'\n",
    "\n",
    "transform = functools.partial(Abed_utils.normalize_input, im_size=im_size, patch_size=patch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): VisionTransformer(\n    (patch_embed): PatchEmbed(\n      (proj): Conv2d(3, 384, kernel_size=(8, 8), stride=(8, 8))\n    )\n    (pos_drop): Dropout(p=0.0, inplace=False)\n    (blocks): ModuleList(\n      (0): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): Identity()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): GELU()\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (1): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): Identity()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): GELU()\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (2): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): Identity()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): GELU()\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (3): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): Identity()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): GELU()\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (4): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): Identity()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): GELU()\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (5): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): Identity()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): GELU()\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (6): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): Identity()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): GELU()\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (7): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): Identity()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): GELU()\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (8): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): Identity()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): GELU()\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (9): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): Identity()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): GELU()\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (10): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): Identity()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): GELU()\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (11): Block(\n        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=384, out_features=384, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): Identity()\n        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n          (act): GELU()\n          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n    (head): Identity()\n  )\n  (1): ClassificationHead(\n    (mlp): Sequential(\n      (0): Dropout(p=0.2, inplace=False)\n      (1): Linear(in_features=384, out_features=9, bias=True)\n    )\n  )\n)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone = Abed_utils.get_vit(patch_size, path_to_backbone)\n",
    "\n",
    "classifier = Abed_utils.ClassificationHead(pretrained_path=path_to_classifier)\n",
    "# features, labels = Abed_utils.load_features(os.path.join(Abed_utils.OUTPUT_ROOT, 'features'), cuda=True)\n",
    "# classifier = Abed_utils.KNNClassifier(features, labels)\n",
    "model = nn.Sequential(backbone, classifier)\n",
    "# model = classifier\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4006/4006 [20:07<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 001b_B2005.30530_C_HE.mrxs we get an accuracy of 0.4220 and an f1 of 0.4220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3322/3322 [17:04<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 352b_B2005.5775_F_HE.mrxs we get an accuracy of 0.0370 and an f1 of 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3362/3362 [17:23<00:00,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 565c_B2012.15587_B_HE.mrxs we get an accuracy of 0.1799 and an f1 of 0.1799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if Abed_utils.BERN_TILES_ROOT is None:\n",
    "    raise RuntimeError('labelled Bern tiles not available on this machine, run on the dataserver')\n",
    "\n",
    "wsis = os.listdir(Abed_utils.BERN_TILES_ROOT)\n",
    "with torch.no_grad():\n",
    "    for wsi in wsis:\n",
    "        acc = 0\n",
    "        f1 = 0\n",
    "        ds = ImageFolder(os.path.join(Abed_utils.BERN_TILES_ROOT, wsi), transform=transform)\n",
    "        # features, labels = Abed_utils.load_features(os.path.join(Abed_utils.OUTPUT_ROOT, f'features-{wsi}'), cuda=True)\n",
    "        # ds = TensorDataset(features, labels)\n",
    "        data = DataLoader(ds, batch_size=batch_size)\n",
    "        preds = np.empty(len(ds))\n",
    "        targets = np.empty_like(preds)\n",
    "        for i, (x, y) in enumerate(tqdm(data)):\n",
    "            idx = slice(i*batch_size,min((i+1)*batch_size, preds.shape[0]))\n",
    "            predictions = model(x.cuda()).cpu().numpy()\n",
    "            preds[idx] = predictions if len(predictions.shape) < 2 else predictions.argmax(axis=1)\n",
    "            targets[idx] = y.cpu().numpy()\n",
    "\n",
    "        acc = (preds == targets).mean()\n",
    "        f1 = f1_score(targets, preds, average='micro')\n",
    "        print(f'for {wsi} we get an accuracy of {acc:.4f} and an f1 of {f1:.4f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}