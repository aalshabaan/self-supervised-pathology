{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# KNN classification and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "import Abed_utils\n",
    "from facebookresearch_dino_main.eval_knn import knn_classifier as dino_knn\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Extraction\n",
    "This is done in the file `extract_embeddings.py`. We simply store the output of the model and the label for each tile\n",
    "## Define KNN classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def distance_matrix(x, y=None, p = 2): #pairwise distance of vectors\n",
    "\n",
    "    y = x if type(y) == type(None) else y\n",
    "    x = x.cpu()\n",
    "    y = y.cpu()\n",
    "\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "\n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "\n",
    "    dist = torch.pow(x - y, p).sum(2)\n",
    "\n",
    "    return dist\n",
    "\n",
    "@torch.no_grad()\n",
    "def knn_classifier(train_features:torch.Tensor, train_labels, test_features, test_labels, k:int):\n",
    "\n",
    "    num_test_images, num_chunks = test_labels.shape[0], 100\n",
    "    imgs_per_chunk = num_test_images // num_chunks\n",
    "    preds = torch.zeros_like(test_labels).cpu()\n",
    "\n",
    "    for idx in range(0, num_test_images, imgs_per_chunk):\n",
    "        features = test_features[idx:min(idx+imgs_per_chunk, num_test_images), :].cpu()\n",
    "        targets = test_labels[idx:min(idx+imgs_per_chunk, num_test_images)].cpu()\n",
    "        dists = distance_matrix(features, train_features)\n",
    "        _, voters = torch.topk(dists, k, largest=False)\n",
    "        votes = torch.gather(train_labels.view(1, -1).expand(targets.shape[0], -1),1, voters)\n",
    "        batch_preds, _ = torch.mode(votes, 1)\n",
    "        preds[idx : min((idx + imgs_per_chunk), num_test_images)] = batch_preds\n",
    "\n",
    "    return preds\n",
    "\n",
    "@torch.no_grad()\n",
    "def similarity_knn_classifier(train_features:torch.Tensor, train_labels:torch.Tensor, test_features:torch.Tensor, test_labels:torch.Tensor, k:int):\n",
    "\n",
    "    num_test_images, num_chunks = test_labels.shape[0], 100\n",
    "    imgs_per_chunk = num_test_images // num_chunks\n",
    "    train_feats_transpose = train_features.t()\n",
    "\n",
    "    preds = torch.zeros_like(test_labels)\n",
    "    for idx in range(0, num_test_images, imgs_per_chunk):\n",
    "        # get the features for test images\n",
    "        features = test_features[idx:min((idx+imgs_per_chunk), num_test_images), :]\n",
    "        targets = test_labels[idx:min((idx+imgs_per_chunk), num_test_images)]\n",
    "        similarities = features.mm(train_feats_transpose).t().div(features.norm(2,1)).t().div(train_features.norm(2,1))\n",
    "        _, voters = torch.topk(similarities, k, 1)\n",
    "        votes = torch.gather(train_labels.view(1, -1).expand(targets.shape[0], -1),1, voters)\n",
    "        batch_preds, _ = torch.mode(votes, 1)\n",
    "        preds[idx : min((idx + imgs_per_chunk), num_test_images)] = batch_preds\n",
    "\n",
    "    return preds\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def weighted_similarity_knn_classifier(train_features, train_labels, test_features, test_labels, k, T, num_classes=1000):\n",
    "\n",
    "    # top1, top5, total = 0.0, 0.0, 0\n",
    "    train_features = train_features.t()\n",
    "    num_test_images, num_chunks = test_labels.shape[0], 100\n",
    "    imgs_per_chunk = num_test_images // num_chunks\n",
    "    retrieval_one_hot = torch.zeros(k, num_classes).to(train_features.device)\n",
    "    preds = torch.zeros_like(test_labels)\n",
    "    for idx in range(0, num_test_images, imgs_per_chunk):\n",
    "        # get the features for test images\n",
    "        features = test_features[\n",
    "            idx : min((idx + imgs_per_chunk), num_test_images), :\n",
    "        ]\n",
    "        targets = test_labels[idx : min((idx + imgs_per_chunk), num_test_images)]\n",
    "        batch_size = targets.shape[0]\n",
    "\n",
    "        # calculate the dot product and compute top-k neighbors\n",
    "        similarity = torch.mm(features, train_features)\n",
    "        distances, indices = similarity.topk(k, largest=True, sorted=True)\n",
    "        candidates = train_labels.view(1, -1).expand(batch_size, -1)\n",
    "        retrieved_neighbors = torch.gather(candidates, 1, indices)\n",
    "\n",
    "        retrieval_one_hot.resize_(batch_size * k, num_classes).zero_()\n",
    "        retrieval_one_hot.scatter_(1, retrieved_neighbors.view(-1, 1), 1)\n",
    "        distances_transform = distances.clone().div_(T).exp_()\n",
    "        probs = torch.sum(\n",
    "            torch.mul(\n",
    "                retrieval_one_hot.view(batch_size, -1, num_classes),\n",
    "                distances_transform.view(batch_size, -1, 1),\n",
    "            ),\n",
    "            1,\n",
    "        )\n",
    "        _, predictions = probs.sort(1, True)\n",
    "        # return predictions\n",
    "        # print(predictions.shape)\n",
    "        preds[idx:min(idx+imgs_per_chunk, num_test_images)] = predictions[:,-1]\n",
    "\n",
    "        # find the predictions that match the target\n",
    "        # correct = predictions.eq(targets.data.view(-1, 1))\n",
    "        # top1 = top1 + correct.narrow(1, 0, 1).sum().item()\n",
    "        # top5 = top5 + correct.narrow(1, 0, min(5, k)).sum().item()  # top5 does not make sense if k < 5\n",
    "        # total += targets.size(0)\n",
    "    return preds\n",
    "    # top1 = top1 * 100.0 / total\n",
    "    # top5 = top5 * 100.0 / total\n",
    "    # return top1, top5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load features and labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features is of shape torch.Size([100000, 384]) and is on cpu\n",
      "labels is of shape torch.Size([100000]) and is on cpu\n"
     ]
    }
   ],
   "source": [
    "feat_path = os.path.join(Abed_utils.OUTPUT_ROOT, 'features_tuned')\n",
    "\n",
    "features = torch.load(os.path.join(feat_path, 'features.pt'))\n",
    "labels = torch.load(os.path.join(feat_path, 'labels.pt'))\n",
    "\n",
    "print(f'features is of shape {features.shape} and is on {features.device}')\n",
    "print(f'labels is of shape {labels.shape} and is on {labels.device}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# K-Fold CV\n",
    "seed = 42\n",
    "n_folds = 10\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "k_fold = KFold(n_splits=n_folds, random_state=seed, shuffle=True)\n",
    "\n",
    "features = features.to(device)\n",
    "labels = labels.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [06:41, 40.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold CV shows:\n",
      "average accuracy: 90.48%, average f1: 0.90 for cos similarity KNN,\n",
      "average accuracy: 61.47%, average f1: 0.61 for weighted KNN,\n",
      "average accuracy: 90.49%, average f1: 0.90 for base KNN,\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10it [06:47, 40.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold CV shows:\n",
      "average accuracy: 90.48%, average f1: 0.90 for cos similarity KNN,\n",
      "average accuracy: 61.47%, average f1: 0.61 for weighted KNN,\n",
      "average accuracy: 90.49%, average f1: 0.90 for base KNN,\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10it [07:04, 42.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold CV shows:\n",
      "average accuracy: 90.48%, average f1: 0.90 for cos similarity KNN,\n",
      "average accuracy: 61.47%, average f1: 0.61 for weighted KNN,\n",
      "average accuracy: 90.49%, average f1: 0.90 for base KNN,\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter for KNN classification\n",
    "K = 20\n",
    "acc_sim = []\n",
    "acc_weighted = []\n",
    "acc_base = []\n",
    "f1_sim = []\n",
    "f1_weighted = []\n",
    "f1_base = []\n",
    "acc_dino = []\n",
    "acc_dino_5 = []\n",
    "# auc_base = []\n",
    "# auc_weighted = []\n",
    "\n",
    "base_knn = KNeighborsClassifier(K)\n",
    "\n",
    "for train_idx, val_idx in tqdm(k_fold.split(features, labels)):\n",
    "    X_train, X_test = features[train_idx], features[val_idx]\n",
    "    y_train, y_test = labels[train_idx], labels[val_idx]\n",
    "\n",
    "    y_test_cpu = y_test.cpu()\n",
    "\n",
    "    preds_sim = similarity_knn_classifier(X_train, y_train, X_test, y_test, K).cpu()\n",
    "    preds_weighted = weighted_similarity_knn_classifier(X_train, y_train, X_test, y_test, K, 0.07, 9).cpu()\n",
    "    preds_base = base_knn.fit(X_train.cpu(), y_train.cpu()).predict(X_test.cpu())\n",
    "\n",
    "    acc_sim.append(preds_sim.eq(y_test_cpu).float().mean())\n",
    "    f1_sim.append(f1_score(y_test_cpu, preds_sim, average='micro'))\n",
    "    # auc_base.append(roc_auc_score(y_test_cpu, preds_base, average='micro', multi_class='ovr'))\n",
    "\n",
    "    acc_weighted.append(preds_weighted.eq(y_test_cpu).float().mean())\n",
    "    f1_weighted.append(f1_score(y_test_cpu, preds_weighted, average='micro'))\n",
    "    # auc_weighted.append(roc_auc_score(y_test_cpu, preds_weighted, average='micro', multi_class='ovr'))\n",
    "\n",
    "    acc_base.append((preds_base == y_test_cpu.numpy()).mean())\n",
    "    f1_base.append(f1_score(y_test_cpu, preds_base, average='micro'))\n",
    "\n",
    "    # acc, acc5 = dino_knn(X_train, y_train, X_test, y_test, K, 0.07, 9)\n",
    "    # acc_dino.append(acc)\n",
    "    # acc_dino_5.append(acc5)\n",
    "\n",
    "print(f'{n_folds}-fold CV shows:\\n'\n",
    "      f'average accuracy: {100*np.mean(acc_sim):.2f}%, average f1: {np.mean(f1_sim):.2f} for cos similarity KNN,\\n'\n",
    "      f'average accuracy: {100*np.mean(acc_weighted):.2f}%, average f1: {np.mean(f1_weighted):.2f} for weighted KNN,\\n'\n",
    "      f'average accuracy: {100*np.mean(acc_base):.2f}%, average f1: {np.mean(f1_base):.2f} for base KNN,\\n')\n",
    "      # f'average accuracy: {np.mean(acc_dino):.2f}% and a top5 acc: {np.mean(acc_dino_5)}% with the dino KNN implementation')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}